# highCompute.py

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)  

A single Python file that connects via the OpenAI Chat Completions API, giving you something akin to OpenAI High Compute at home. **Any** models are compatible. Using dynamic programming methods, computational capacity is increased by tens or even hundreds of times for both reasoning and non-reasoning models, significantly improving answer quality and the ability to solve extremely complex tasks for LLMs.  

This is a simple Gradio-based web application providing an interface for interacting with a locally hosted Large Language Model (LLM). The key feature is the ability to select a "Computation Level," which determines the strategy for processing user queries‚Äîranging from direct responses to multi-level task decomposition for obtaining more structured and comprehensive answers to complex queries.  

![image](https://github.com/user-attachments/assets/8886405d-9a49-41ca-89d1-900fdc136d8d)  

The application connects to your specified LLM API endpoint, compatible with the OpenAI Chat Completions API format.  

## üåü Key Features  

*   **Local LLM Integration:** Works with your own LLM server (e.g., llama.cpp, Ollama, LM Studio, vLLM with an OpenAI-compatible endpoint).  
*   **Compute Levels:**  
    *   **Low:** Direct query to the LLM for a quick response. Generates N tokens.  
    *   **Medium:** Single-level task decomposition into subtasks, solving them, and synthesizing the answer. Suitable for moderately complex queries. The number of generated tokens roughly squares compared to Low compute. Generates N¬≤ tokens.  
    *   **High:** Two-level task decomposition (stages ‚Üí steps), solving individual steps, synthesizing stage results, and generating a final comprehensive answer. Designed for highly complex and multi-component tasks. The number of generated tokens roughly cubes compared to Low compute. Generates N¬≥ tokens. 

## ‚öôÔ∏è How It Works: Computation Levels  

The core idea is that for complex tasks, a simple direct query to the LLM may not yield optimal results. Decomposition allows breaking down a complex problem into smaller, manageable parts, solving them individually, and then combining the results.  

1.  **Low:**  
    *   `User Query` ‚Üí `LLM (single call)` ‚Üí `Response`  
    *   The fastest mode, suitable for simple questions or when a quick response is needed. Essentially, this is the standard chat mode.  

2.  **Medium:**  
    *   `User Query` ‚Üí `LLM (decomposition request)` ‚Üí `List of subtasks`  
    *   *For each subtask:* `Subtask + Context` ‚Üí `LLM (subtask solution)` ‚Üí `Subtask result`  
    *   `All subtask results + Original query` ‚Üí `LLM (final synthesis)` ‚Üí `Final answer`  
    *   Uses multiple LLM calls. Decomposition and synthesis requests use a lower `temperature` for greater predictability.  

3.  **High:**  
    *   `User Query` ‚Üí `LLM (Level 1 decomposition)` ‚Üí `List of stages (L1)`  
    *   *For each L1 stage:*  
        *   `L1 Stage + Context` ‚Üí `LLM (Level 2 decomposition)` ‚Üí `List of steps (L2)`  
        *   *If L2 decomposition is not needed:* `L1 Stage + Context` ‚Üí `LLM (direct L1 stage solution)` ‚Üí `L1 Stage result`  
        *   *If L2 decomposition succeeds:*  
            *   *For each L2 step:* `L2 Step + L1 Context` ‚Üí `LLM (L2 step solution)` ‚Üí `L2 Step result`  
            *   `All L2 Step results + L1 Context` ‚Üí `LLM (L1 stage synthesis)` ‚Üí `L1 Stage result`  
    *   `All L1 Stage results + Original query` ‚Üí `LLM (final synthesis)` ‚Üí `Final answer`  
    *   The most resource-intensive mode, using multiple LLM calls. Designed for highly complex tasks requiring multi-stage planning and solving. Uses a lower `temperature` for all decomposition and synthesis steps. If L1 decomposition fails, it automatically switches to `Medium` mode. WARNING! This can increase the number of generated tokens by hundreds of times! If you're using a paid API, consider this carefully!  

## üìã Prerequisites  

*   **Python 3.11+**  
*   **pip** (Python package manager)  
*   **A working LLM server:** You need an accessible HTTP server with an LLM that provides an API compatible with [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat/create).  
    *   Examples of such servers:  
        *   [Ollama](https://ollama.ai/) (with the `--api` flag or via a separate proxy for OpenAI compatibility)  
        *   [LM Studio](https://lmstudio.ai/) (provides an OpenAI-compatible endpoint)  
        *   [vLLM](https://github.com/vllm-project/vllm) (with an OpenAI-compatible server)  
        *   [OpenRouter](https://openrouter.ai/).  
    *   **Important:** The server must accept POST requests at the path specified in `LLM_API_ENDPOINT` (default: `/v1/chat/completions`) and process JSON data in OpenAI format (fields: `model`, `messages`, `temperature`, `top_p`, `top_k`). The response must also follow the OpenAI format (expected field: `choices[0].message.content`).  

## üöÄ Installation  

1.  **Clone the repository:**  
    ```bash  
    git clone https://github.com/AlexBefest/highCompute.py.git
    cd highCompute.py  
    ```  

2.  **Create and activate a virtual environment (recommended):**  
    *   On Linux/macOS:  
        ```bash  
        python3 -m venv venv  
        source venv/bin/activate  
        ```  
    *   On Windows:  
        ```bash  
        python -m venv venv  
        .\venv\Scripts\activate  
        ```  

3.  **Install dependencies:**  
    Install Python dependencies:  
    ```bash  
    pip install -r requirements.txt  
    ```  

## ‚öôÔ∏è Configuration  

1.  **Create a `.env` file** in the project root folder.  
2.  **Add `LLM_API_ENDPOINT`, `LLM_MODEL`, and `LLM_API_KEY` to `.env`**, specifying the full URL of your local LLM API endpoint compatible with OpenAI Chat Completions API, your LLM model name, and API key.  

    **Example `.env` file content:**  
    ```dotenv  
    LLM_API_ENDPOINT=http://192.168.2.33:8000/v1/chat/completions  
    LLM_API_KEY="token-abc123"  
    LLM_MODEL="AlexBefest/Gemma3-27B"  
    ```  
    *   Ensure your LLM server is actually listening at this address and path.  

## ‚ñ∂Ô∏è Running the Application  

1.  **Ensure your local LLM server is running** and accessible at the URL specified in `.env` (or the default address).  
2.  **Run the Python script:**  
    ```bash  
    python highCompute.py  
    ```  
3.  **Open the web interface:** The console will display a Gradio message with the local URL, typically `http://127.0.0.1:7860`. Open this URL in your web browser.  

## üí¨ Using the Interface  

1.  **Select Computation Level:** Low, Medium, or High, depending on query complexity.  
2.  **(Optional) Adjust parameters:** Modify the `Temperature`, `Top-P`, and `Top-K` sliders if you want to change the LLM's response style.  
    *   `Temperature`: Controls randomness. Lower values (closer to 0) make responses more deterministic and focused. Higher values (closer to 2.0) make responses more creative and diverse but may lead to "hallucinations."  
    *   `Top-P`: Nucleus sampling. The model only considers tokens whose cumulative probability is ‚â• `top_p`. A value of `1.0` disables this parameter.  
    *   `Top-K`: Only the top `k` most probable tokens are considered. A value of `0` disables this parameter.  
3.  **Enter your query:** Type your message in the "Your message" text field at the bottom.  
4.  **Submit the query:** Press Enter or click the "Submit" button.  
5.  **View the response:** The LLM's answer will appear in the chat window.  
6.  **Continue the conversation:** Enter follow-up messages. Chat history is preserved and passed to the LLM for context.  
7.  **Clear chat:** Click the "Clear Chat" button to reset history and start a new conversation.  

## ‚ö†Ô∏è Important Notes & Troubleshooting  

*   **LLM API Compatibility:** Ensure your LLM endpoint *strictly* follows the OpenAI Chat Completions API format for requests and responses. Incompatibility will cause errors.  
*   **Performance:** `Medium` and especially `High` modes perform multiple sequential LLM calls, significantly increasing response time compared to `Low` mode.  
*   **Decomposition Quality:** The success of `Medium` and `High` modes heavily depends on the LLM's ability to understand and execute decomposition and synthesis instructions. Quality may vary based on the LLM model and task complexity. Sometimes, the LLM may fail to decompose the task or return a response not in a numbered list format.  
*   **Method Efficiency:** Note that this method may be inefficient with smaller models.  
*   **Network Errors:** If you see "Network error," check if your LLM server is running and accessible at the `.env`-specified address. Verify network and firewall settings.  
*   **JSON Errors:** If you see "Error: Failed to decode JSON response" or "Invalid format," this means the LLM server returned a response that is not valid JSON or does not match the expected OpenAI structure. Check your LLM server logs.

***

# highCompute.py

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

–í—Å–µ–≥–æ –æ–¥–∏–Ω python-—Ñ–∞–π–ª, –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ OpenAI Chat Completions API, –∏ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ OpenAI High Compute at home. –°–æ–≤–º–µ—Å—Ç–∏–º—ã **–ª—é–±—ã–µ** –º–æ–¥–µ–ª–∏. –ò—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –≤ –¥–µ—Å—è—Ç–∫–∏ –∏ —Å–æ—Ç–Ω–∏ —Ä–∞–∑ –¥–ª—è reasoning –∏ no-reasoning –º–æ–¥–µ–ª–µ–π, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ–≤—ã—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤ –∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ä–µ—à–∞—Ç—å —á—Ä–µ–∑–≤—ã—á–∞–π–Ω–æ —Å–ª–æ–∂–Ω—ã–µ –¥–ª—è LLM –∑–∞–¥–∞—á–∏. 

–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ–µ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –±–∞–∑–µ Gradio, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–µ–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ª–æ–∫–∞–ª—å–Ω–æ –∑–∞–ø—É—â–µ–Ω–Ω–æ–π –ë–æ–ª—å—à–æ–π –Ø–∑—ã–∫–æ–≤–æ–π –ú–æ–¥–µ–ª—å—é (LLM). –ö–ª—é—á–µ–≤–æ–π –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é —è–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ "–£—Ä–æ–≤–Ω—è –í—ã—á–∏—Å–ª–µ–Ω–∏–π" (Computation Level), –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: –æ—Ç –ø—Ä—è–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–æ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–π –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ –ø–æ–ª–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —Å–ª–æ–∂–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã.

![image](https://github.com/user-attachments/assets/8886405d-9a49-41ca-89d1-900fdc136d8d)


–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –≤–∞–º–∏ API-—ç–Ω–¥–ø–æ–∏–Ω—Ç—É LLM, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º—É —Å —Ñ–æ—Ä–º–∞—Ç–æ–º OpenAI Chat Completions API.

## üåü –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

*   **–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM:** –†–∞–±–æ—Ç–∞–µ—Ç —Å –≤–∞—à–∏–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º LLM-—Å–µ—Ä–≤–µ—Ä–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, llama.cpp, Ollama, LM Studio, vLLM —Å OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–º).
*   **–£—Ä–æ–≤–Ω–∏ –í—ã—á–∏—Å–ª–µ–Ω–∏–π:**
    *   **Low (–ù–∏–∑–∫–∏–π):** –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è N-—Ç–æ–∫–µ–Ω–æ–≤
    *   **Medium (–°—Ä–µ–¥–Ω–∏–π):** –û–¥–Ω–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –∑–∞–¥–∞—á–∏ –Ω–∞ –ø–æ–¥–∑–∞–¥–∞—á–∏, –∏—Ö —Ä–µ—à–µ–Ω–∏–µ –∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏–π —Å–∏–Ω—Ç–µ–∑ –æ—Ç–≤–µ—Ç–∞. –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —É–º–µ—Ä–µ–Ω–Ω–æ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤–æ–∑–≤–æ–¥–∏—Ç—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ –∫–≤–∞–¥—Ä–∞—Ç –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ low compute. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è N^2 —Ç–æ–∫–µ–Ω–æ–≤.
    *   **High (–í—ã—Å–æ–∫–∏–π):** –î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –∑–∞–¥–∞—á–∏ (—ç—Ç–∞–ø—ã -> —à–∞–≥–∏), —Ä–µ—à–µ–Ω–∏–µ —à–∞–≥–æ–≤, —Å–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç—Ç–∞–ø–æ–≤ –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑ –æ–±—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞. –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –Ω–∞–∏–±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã—Ö –∏ –º–Ω–æ–≥–æ–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤–æ–∑–≤–æ–¥–∏—Ç—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ –≤ –∫—É–± –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ low compute. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è N^3 —Ç–æ–∫–µ–Ω–æ–≤

## ‚öôÔ∏è –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç: –£—Ä–æ–≤–Ω–∏ –í—ã—á–∏—Å–ª–µ–Ω–∏–π

–û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á –ø—Ä–æ—Å—Ç–æ–π –ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ LLM –º–æ–∂–µ—Ç –Ω–µ –¥–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–∑–±–∏—Ç—å —Å–ª–æ–∂–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É –Ω–∞ –±–æ–ª–µ–µ –º–µ–ª–∫–∏–µ, —É–ø—Ä–∞–≤–ª—è–µ–º—ã–µ —á–∞—Å—Ç–∏, —Ä–µ—à–∏—Ç—å –∏—Ö –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏, –∞ –∑–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.

1.  **Low (–ù–∏–∑–∫–∏–π):**
    *   `–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å` -> `LLM (–æ–¥–∏–Ω –≤—ã–∑–æ–≤)` -> `–û—Ç–≤–µ—Ç`
    *   –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–ª–∏ –∫–æ–≥–¥–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±—ã—Å—Ç—Ä–∞—è —Ä–µ–∞–∫—Ü–∏—è. –§–∞–∫—Ç–∏—á–µ—Å–∫–∏, —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∂–∏–º —á–∞—Ç–∞.

2.  **Medium (–°—Ä–µ–¥–Ω–∏–π):**
    *   `–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å` -> `LLM (–∑–∞–ø—Ä–æ—Å –Ω–∞ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—é)` -> `–°–ø–∏—Å–æ–∫ –ø–æ–¥–∑–∞–¥–∞—á`
    *   *–î–ª—è –∫–∞–∂–¥–æ–π –ø–æ–¥–∑–∞–¥–∞—á–∏:* `–ü–æ–¥–∑–∞–¥–∞—á–∞ + –ö–æ–Ω—Ç–µ–∫—Å—Ç` -> `LLM (—Ä–µ—à–µ–Ω–∏–µ –ø–æ–¥–∑–∞–¥–∞—á–∏)` -> `–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–¥–∑–∞–¥–∞—á–∏`
    *   `–í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥–∑–∞–¥–∞—á + –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å` -> `LLM (—Å–∏–Ω—Ç–µ–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞)` -> `–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç`
    *   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—ã–∑–æ–≤–æ–≤ LLM. –ó–∞–ø—Ä–æ—Å—ã –Ω–∞ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—é –∏ —Å–∏–Ω—Ç–µ–∑ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø–æ–Ω–∏–∂–µ–Ω–Ω—É—é `temperature` –¥–ª—è –±–æ–ª—å—à–µ–π –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏.

3.  **High (–í—ã—Å–æ–∫–∏–π):**
    *   `–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å` -> `LLM (–¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –£—Ä–æ–≤–Ω—è 1)` -> `–°–ø–∏—Å–æ–∫ —ç—Ç–∞–ø–æ–≤ (L1)`
    *   *–î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ L1:*
        *   `–≠—Ç–∞–ø L1 + –ö–æ–Ω—Ç–µ–∫—Å—Ç` -> `LLM (–¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –£—Ä–æ–≤–Ω—è 2)` -> `–°–ø–∏—Å–æ–∫ —à–∞–≥–æ–≤ (L2)`
        *   *–ï—Å–ª–∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è L2 –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è:* `–≠—Ç–∞–ø L1 + –ö–æ–Ω—Ç–µ–∫—Å—Ç` -> `LLM (–ø—Ä—è–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ —ç—Ç–∞–ø–∞ L1)` -> `–†–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–∞–ø–∞ L1`
        *   *–ï—Å–ª–∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è L2 —É–¥–∞–ª–∞—Å—å:*
            *   *–î–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ L2:* `–®–∞–≥ L2 + –ö–æ–Ω—Ç–µ–∫—Å—Ç L1` -> `LLM (—Ä–µ—à–µ–Ω–∏–µ —à–∞–≥–∞ L2)` -> `–†–µ–∑—É–ª—å—Ç–∞—Ç —à–∞–≥–∞ L2`
            *   `–í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —à–∞–≥–æ–≤ L2 + –ö–æ–Ω—Ç–µ–∫—Å—Ç L1` -> `LLM (—Å–∏–Ω—Ç–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —ç—Ç–∞–ø–∞ L1)` -> `–†–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–∞–ø–∞ L1`
    *   `–í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–æ–≤ L1 + –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å` -> `LLM (—Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–Ω—Ç–µ–∑)` -> `–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç`
    *   –°–∞–º—ã–π —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–∏–π —Ä–µ–∂–∏–º, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–Ω–æ–∂–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤ LLM. –ü—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á, —Ç—Ä–µ–±—É—é—â–∏—Ö –º–Ω–æ–≥–æ—ç—Ç–∞–ø–Ω–æ–≥–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ä–µ—à–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–Ω–∏–∂–µ–Ω–Ω—É—é `temperature` –¥–ª—è –≤—Å–µ—Ö —à–∞–≥–æ–≤ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –∏ —Å–∏–Ω—Ç–µ–∑–∞. –ï—Å–ª–∏ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è L1 –Ω–µ —É–¥–∞–µ—Ç—Å—è, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Ä–µ–∂–∏–º `Medium`. –í–ù–ò–ú–ê–ù–ò–ï! –ú–æ–∂–µ—Ç —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–æ—Ç–Ω–∏ —Ä–∞–∑! –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø–ª–∞—Ç–Ω—ã–π API, –≤–∞–º —Å—Ç–æ–∏—Ç —ç—Ç–æ —É—á–∏—Ç—ã–≤–∞—Ç—å!

## üìã –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

*   **Python 3.11+**
*   **pip** (–º–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–∫–µ—Ç–æ–≤ Python)
*   **–†–∞–±–æ—Ç–∞—é—â–∏–π LLM —Å–µ—Ä–≤–µ—Ä:** –í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø–æ HTTP —Å–µ—Ä–≤–µ—Ä —Å LLM, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç API, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–µ —Å [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat/create).
    *   –ü—Ä–∏–º–µ—Ä—ã —Ç–∞–∫–∏—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤:
        *   [Ollama](https://ollama.ai/) (—Å —Ñ–ª–∞–≥–æ–º `--api` –∏–ª–∏ —á–µ—Ä–µ–∑ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è OpenAI —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        *   [LM Studio](https://lmstudio.ai/) (–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç)
        *   [vLLM](https://github.com/vllm-project/vllm) (—Å OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º —Å–µ—Ä–≤–µ—Ä–æ–º)
        *   [OpenRouter](https://openrouter.ai/).
    *   **–í–∞–∂–Ω–æ:** –°–µ—Ä–≤–µ—Ä –¥–æ–ª–∂–µ–Ω –ø—Ä–∏–Ω–∏–º–∞—Ç—å POST-–∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø—É—Ç—å, —É–∫–∞–∑–∞–Ω–Ω—ã–π –≤ `LLM_API_ENDPOINT` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é `/v1/chat/completions`), –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å JSON-–¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI (–ø–æ–ª—è `model`, `messages`, `temperature`, `top_p`, `top_k`). –û—Ç–≤–µ—Ç —Ç–∞–∫–∂–µ –¥–æ–ª–∂–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç—É OpenAI (–æ–∂–∏–¥–∞–µ—Ç—Å—è –ø–æ–ª–µ `choices[0].message.content`).

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

1.  **–ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:**
    ```bash
    git clone https://github.com/AlexBefest/highCompute.py.git
    cd highCompute.py
    ```

2.  **–°–æ–∑–¥–∞–π—Ç–µ –∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):**
    *   –ù–∞ Linux/macOS:
        ```bash
        python3 -m venv venv
        source venv/bin/activate
        ```
    *   –ù–∞ Windows:
        ```bash
        python -m venv venv
        .\venv\Scripts\activate
        ```

3.  **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
    –í—ã–ø–æ–ª–Ω–∏—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É python-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:
    ```bash
    pip install -r requirements.txt
    ```

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

1.  **–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env`** –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞.
2.  **–î–æ–±–∞–≤—å—Ç–µ –≤ `.env` –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `LLM_API_ENDPOINT`, `LLM_MODEL` –∏ `LLM_API_KEY`**, —É–∫–∞–∑–∞–≤ –ø–æ–ª–Ω—ã–π URL –≤–∞—à–µ–≥–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ LLM API —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–≤–º–µ—Å—Ç–∏–º —Å OpenAI Chat Completions API. –ê —Ç–∞–∫–∂–µ –∏–º—è –≤–∞—à–µ–π LLM-–º–æ–¥–µ–ª–∏ –∏ API-–∫–ª—é—á.

    **–ü—Ä–∏–º–µ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞ `.env`:**
    ```dotenv
    LLM_API_ENDPOINT=http://192.168.2.33:8000/v1/chat/completions
    LLM_API_KEY="token-abc123"
    LLM_MODEL ="AlexBefest/Gemma3-27B"
    ```
    *   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à LLM —Å–µ—Ä–≤–µ—Ä –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–ª—É—à–∞–µ—Ç —ç—Ç–æ—Ç –∞–¥—Ä–µ—Å –∏ –ø—É—Ç—å.

## ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

1.  **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –ª–æ–∫–∞–ª—å–Ω—ã–π LLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω** –∏ –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ URL, —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –≤ —Ñ–∞–π–ª–µ `.env` (–∏–ª–∏ –ø–æ –∞–¥—Ä–µ—Å—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é).
2.  **–ó–∞–ø—É—Å—Ç–∏—Ç–µ Python —Å–∫—Ä–∏–ø—Ç:**
    ```bash
    python highCompute.py
    ```
3.  **–û—Ç–∫—Ä–æ–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å:** –í –∫–æ–Ω—Å–æ–ª–∏ –≤—ã —É–≤–∏–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç Gradio —Å –ª–æ–∫–∞–ª—å–Ω—ã–º URL, –æ–±—ã—á–Ω–æ `http://127.0.0.1:7860`. –û—Ç–∫—Ä–æ–π—Ç–µ —ç—Ç–æ—Ç URL –≤ –≤–∞—à–µ–º –≤–µ–±-–±—Ä–∞—É–∑–µ—Ä–µ.

## üí¨ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞

1.  **–í—ã–±–µ—Ä–∏—Ç–µ –£—Ä–æ–≤–µ–Ω—å –í—ã—á–∏—Å–ª–µ–Ω–∏–π (Computation Level):** Low, Medium –∏–ª–∏ High, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
2.  **(–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:** –û—Ç—Ä–µ–≥—É–ª–∏—Ä—É–π—Ç–µ –ø–æ–ª–∑—É–Ω–∫–∏ `Temperature`, `Top-P`, `Top-K`, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —Å—Ç–∏–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ LLM.
    *   `Temperature`: –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å. –ù–∏–∑–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (–±–ª–∏–∂–µ –∫ 0) –¥–µ–ª–∞—é—Ç –æ—Ç–≤–µ—Ç—ã –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏. –í—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è (–±–ª–∏–∂–µ –∫ 2.0) –¥–µ–ª–∞—é—Ç –æ—Ç–≤–µ—Ç—ã –±–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–º–∏ –∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏, –Ω–æ –º–æ–≥—É—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ "–≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è–º".
    *   `Top-P`: –ù—É–∫–ª–µ—É—Å–Ω–æ–µ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ. –ú–æ–¥–µ–ª—å —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω—ã, —á—å—è —Å—É–º–º–∞—Ä–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±–æ–ª—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–∞ `top_p`. –ó–Ω–∞—á–µ–Ω–∏–µ `1.0` –æ—Ç–∫–ª—é—á–∞–µ—Ç —ç—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä.
    *   `Top-K`: –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ `k` –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤. –ó–Ω–∞—á–µ–Ω–∏–µ `0` –æ—Ç–∫–ª—é—á–∞–µ—Ç —ç—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä.
3.  **–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:** –ù–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ "Your message" –≤–Ω–∏–∑—É.
4.  **–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∑–∞–ø—Ä–æ—Å:** –ù–∞–∂–º–∏—Ç–µ Enter –∏–ª–∏ –∫–Ω–æ–ø–∫—É "Submit".
5.  **–ü—Ä–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –æ—Ç–≤–µ—Ç:** –û—Ç–≤–µ—Ç LLM –ø–æ—è–≤–∏—Ç—Å—è –≤ –æ–∫–Ω–µ —á–∞—Ç–∞.
6.  **–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –¥–∏–∞–ª–æ–≥:** –í–≤–æ–¥–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è. –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è LLM –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
7.  **–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç:** –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É "Clear Chat", —á—Ç–æ–±—ã —Å–±—Ä–æ—Å–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥.

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è –∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–µ–π

*   **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å LLM API:** –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à LLM —ç–Ω–¥–ø–æ–∏–Ω—Ç *—Å—Ç—Ä–æ–≥–æ* —Å–ª–µ–¥—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É OpenAI Chat Completions API –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤. –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –æ—à–∏–±–∫–∞–º.
*   **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –†–µ–∂–∏–º—ã `Medium` –∏ –æ—Å–æ–±–µ–Ω–Ω–æ `High` –≤—ã–ø–æ–ª–Ω—è—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ LLM, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ä–µ–∂–∏–º–æ–º `Low`.
*   **–ö–∞—á–µ—Å—Ç–≤–æ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏:** –£—Å–ø–µ—Ö —Ä–µ–∂–∏–º–æ–≤ `Medium` –∏ `High` —Å–∏–ª—å–Ω–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ LLM –ø–æ–Ω–∏–º–∞—Ç—å –∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –∏ —Å–∏–Ω—Ç–µ–∑—É. –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–∂–µ—Ç –≤–∞—Ä—å–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –º–æ–¥–µ–ª–∏ LLM –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏—Å—Ö–æ–¥–Ω–æ–π –∑–∞–¥–∞—á–∏. –ò–Ω–æ–≥–¥–∞ LLM –º–æ–∂–µ—Ç –Ω–µ —Å—É–º–µ—Ç—å —Ä–∞–∑–±–∏—Ç—å –∑–∞–¥–∞—á—É –∏–ª–∏ –≤–µ—Ä–Ω—É—Ç—å –æ—Ç–≤–µ—Ç –Ω–µ –≤ –≤–∏–¥–µ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞.
*   **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–∞:** –ù—É–∂–Ω–æ –ø–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ –¥–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω —Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏
*   **–°–µ—Ç–µ–≤—ã–µ –æ—à–∏–±–∫–∏:** –ï—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ "Network error", –ø—Ä–æ–≤–µ—Ä—å—Ç–µ, –∑–∞–ø—É—â–µ–Ω –ª–∏ –≤–∞—à LLM —Å–µ—Ä–≤–µ—Ä –∏ –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ –æ–Ω –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –≤ `.env` –∞–¥—Ä–µ—Å—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ç–∏ –∏ —Ñ–∞–π—Ä–≤–æ–ª–∞.
*   **–û—à–∏–±–∫–∏ JSON:** –ï—Å–ª–∏ –≤—ã –≤–∏–¥–∏—Ç–µ "Error: Failed to decode JSON response" –∏–ª–∏ "Invalid format", —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ LLM —Å–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª –æ—Ç–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º JSON –∏–ª–∏ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ OpenAI. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤–∞—à–µ–≥–æ LLM —Å–µ—Ä–≤–µ—Ä–∞.
